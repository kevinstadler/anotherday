## Logging only relevant measurements in a illuminance/color temperature time series

When continuously measuring the illuminance (lux) and correlated color temperature (Kelvin) of an environment for later replay, it is not necessary to log the entire time series if the changes between measurements are small. Two things should be considered when deciding which measurements to store, and also how often to do readings to begin with:

* the just noticable differences (JND) in illuminance and color temperature by the human perceptual system
* expected baseline noise levels of the light sensor at different brightness levels

### Just noticable differences (JND)

* Human JND for illuminance is [~7.4% of the current illuminance level](https://www.researchgate.net/publication/305319583_Dimming_curve_based_on_the_detectability_and_acceptability_of_illuminance_differences).

* Human JND of correlated color temperature (CCT) is [~100 Kelvin until a CCT 4000, ~500 above 5000
    Kelvin](https://www.elementalled.com/correlated-color-temperature-and-kelvin/)

In terms of logging new measurements one could therefore use something like the following rule of thumb, which logs every measurement that has a greater than 5% change in illuminance, and any absolute change in CCT greater than 100 Kelvin:

`shouldWriteMeasurement? = abs(20*newLux / lastLux - 20) >= 1 || abs(newCct - lastCct) >= 100`

### Noise levels

While the *absolute* digitization error of the sensor for a given gain and integration time is constant for all inputs, when the light count gets too low the *relative* noise level increases greatly, which means that for very dark environments, the measurement-to-measurement differences in illuminance will regularly exceed the 5% threshold simply due to noise. It's therefore necessary to add another condition which checks absolute sensor counts and discards differences which are most likely just the result of noise.

Given a fixed clear count `C`, how much does the calculated lux change by just a single change in count?

Counts per lux are calculated as `cpl = gain * integrationtime / (ga * df) = 1 * 2.4 / 310` (DF = 310 for the TCS34725).

We are interested in the inverse -- *lux per count* (lpc) -- because this gives an idea of the impact of noise (low-level count fluctuations):

```{r luxpercount}
curve(310 / x, from=2.4, to=600, xlab='integration time (ms)', ylab='lux per count', main='lower gain = higher lux per count')
curve(310 / (4*x), from=2.4, to=600, lty=2, add=TRUE)
curve(310 / (16*x), from=2.4, to=600, lty=3, add=TRUE)
curve(310 / (60*x), from=2.4, to=600, lty=4, add=TRUE)
```

The right end of the graph also gives us information about the actual highest theoretical resolution/sensitivity of the sensor at 60x gain and 600ms integration time: `310 / (60 * 600) = .00861 lux` (that's the *normalized* counts though, see below).

But how much is the *relative* change in illuminance from a unit count change? For simplicity's sake let's assume:
```
# no infrared component, i.e.
C = R + G + B
R = G = B = C/3

# coefficients for the TCS34725
lux = (.136 * R + G - .444 * B) / cpl = .692 * C / (3*cpl)
```

Turns out that, when calculating the relative change ratio, the cpl term disappears from the equation, i.e. the relative lux change per unit change in clear count is independent of the gain and integration time.

`relative change = lpc / lux = (1 / cpl) / (.692 * x / (3*cpl)) = 3*cpl / (cpl * .692 * x) = 3 / (.692 * x)`

```{r relativechangepercount}
curve(3 / (.692 * x), from=3, to=333, n=111, xlab='clear count', ylab='relative lux change per unit count difference')
abline(h=.05, lty=3)
```

At a clear count of 3 (the lowest valur plotted), why is the point change greater than 1/3? This has to do with the fact that the different channels are (very) differently weighted. The chart above assumes that the extra count goes into the green channel, which affects the lux calculation most strongly:

```
assume highest gain + longest integration time:
cpl = 60 * 600 / 310

lux(R=1) = .136 / cpl = 0.001171111
lux(G=1) = 1 / cpl = 0.008611111
lux(B=1) = -.444 / cpl < 0 ***
lux(C=3, R=G=B=1) = .692 / cpl = 0.005958889
lux(C=4, extra count in green) = 1.692 / cpl = 0.01457
```

So based on an even count of `C=3` (`.00595 lux`), the extra relative amount of lux added by a single green count (`.00861111`) is `.00861111 / .00595 = 1.447245`, which is also the maximum value in the graph.
